{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"any-agent","text":"<p><code>any-agent</code> is a Python library providing a single interface to different agent frameworks.</p> <p>Warning</p> <p>Compared to traditional code-defined workflows, agent frameworks introduce complexity and demand much more computational power.</p> <p>Before jumping to use one, carefully consider and evaluate how much value you would get compared to manually defining a sequence of tools and LLM calls.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>To define any agent system you will always use the same imports:</p> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\n</code></pre> <p>Note</p> <p>If you plan on using an agent that requires access to an external service (e.g. OpenAI, Mistral, DeepSeek, etc), you'll need to set any relevant environment variables, e.g.</p> <pre><code>export OPENAI_API_KEY=your_api_key_here\nexport DEEPSEEK_API_KEY=your_api_key_here\n</code></pre>"},{"location":"#single-agent","title":"Single Agent","text":"<p>Configure the agent:</p> <pre><code>main_agent = AgentConfig(\n    model_id=\"gpt-4o\",\n    tools=[\"any_agent.tools.search_web\", \"any_agent.tools.visit_webpage\"]\n)\n</code></pre> <p>Choose one of the available frameworks:</p> <pre><code>from random import choice\n\nframework = AgentFramework(\n    choice(\n        [\"langchain\", \"llama_index\", \"openai\", \"smolagents\"]\n    )\n)\n</code></pre> <p>Create and run the agent:</p> <pre><code>agent = AnyAgent.create(framework, main_agent)\n\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"#multi-agent","title":"Multi-Agent","text":"<p>Building on top of the previous example, we can easily extend it to a multi-agent system.</p> <p>Warning</p> <p>A multi-agent system introduces even more complexity than a single agent.</p> <p>As stated before, carefully consider whether you need to adopt this pattern to solve the task.</p> <p>First, configure the <code>main_agent</code>, similar to before:</p> <pre><code>main_agent = AgentConfig(\n    model_id=\"gpt-4o\"\n)\n</code></pre> <p>This agent will act as the \"orchestrator\".</p> <p>Then, configure the list of <code>managed_agents</code>:</p> <pre><code>managed_agents = [\n    AgentConfig(\n        name=\"search_web_agent\",\n        model_id=\"gpt-4o-mini\",\n        description=\"Agent that can search the web\",\n        tools=[\"any_agent.tools.search_web\"]\n    ),\n    AgentConfig(\n        name=\"visit_webpage_agent\",\n        model_id=\"gpt-4o-mini\",\n        description=\"Agent that can visit webpages\",\n        tools=[\"any_agent.tools.visit_webpage\"]\n    )\n]\n</code></pre> <p>You can then create and run the multi-agent:</p> <pre><code>multi_agent = AnyAgent.create(framework, main_agent, managed_agents)\n\nmulti_agent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#any_agent.frameworks","title":"<code>any_agent.frameworks</code>","text":""},{"location":"api/#any_agent.frameworks.AnyAgent","title":"<code>AnyAgent</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base abstract class for all agent implementations.</p> <p>This provides a unified interface for different agent frameworks.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>class AnyAgent(ABC):\n    \"\"\"Base abstract class for all agent implementations.\n\n    This provides a unified interface for different agent frameworks.\n    \"\"\"\n\n    # factory method\n    @classmethod\n    def create(\n        cls,\n        agent_framework: AgentFramework,\n        agent_config: AgentConfig,\n        managed_agents: Optional[list[AgentConfig]] = None,\n    ) -&gt; \"AnyAgent\":\n        if agent_framework == AgentFramework.SMOLAGENTS:\n            from any_agent.frameworks.smolagents import SmolagentsAgent\n\n            return SmolagentsAgent(agent_config, managed_agents=managed_agents)\n        elif agent_framework == AgentFramework.LANGCHAIN:\n            from any_agent.frameworks.langchain import LangchainAgent\n\n            return LangchainAgent(agent_config, managed_agents=managed_agents)\n        elif agent_framework == AgentFramework.OPENAI:\n            from any_agent.frameworks.openai import OpenAIAgent\n\n            return OpenAIAgent(agent_config, managed_agents=managed_agents)\n        elif agent_framework == AgentFramework.LLAMAINDEX:\n            from any_agent.frameworks.llama_index import LlamaIndexAgent\n\n            return LlamaIndexAgent(agent_config, managed_agents=managed_agents)\n        else:\n            raise ValueError(f\"Unsupported agent framework: {agent_framework}\")\n\n    @abstractmethod\n    def _load_agent(self) -&gt; None:\n        \"\"\"Load the agent instance.\"\"\"\n        pass\n\n    @abstractmethod\n    def run(self, prompt: str) -&gt; Any:\n        \"\"\"Run the agent with the given prompt.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def tools(self) -&gt; List[str]:\n        \"\"\"\n        Return the tools used by the agent.\n        This property is read-only and cannot be modified.\n        \"\"\"\n        pass\n\n    def __init__(self):\n        raise NotImplementedError(\n            \"Cannot instantiate the base class AnyAgent, please use the factory method 'AnyAgent.create'\"\n        )\n\n    @property\n    def agent(self):\n        \"\"\"\n        The underlying agent implementation from the framework.\n\n        This property is intentionally restricted to maintain framework abstraction\n        and prevent direct dependency on specific agent implementations.\n\n        If you need functionality that relies on accessing the underlying agent:\n        1. Consider if the functionality can be added to the AnyAgent interface\n        2. Submit a GitHub issue describing your use case\n        3. Contribute a PR implementing the needed functionality\n\n        Raises:\n            NotImplementedError: Always raised when this property is accessed\n        \"\"\"\n        raise NotImplementedError(\n            \"Cannot access the 'agent' property of AnyAgent, if you need to use functionality that relies on the underlying agent framework, please file a Github Issue or we welcome a PR to add the functionality to the AnyAgent class\"\n        )\n</code></pre>"},{"location":"api/#any_agent.frameworks.AnyAgent.agent","title":"<code>agent</code>  <code>property</code>","text":"<p>The underlying agent implementation from the framework.</p> <p>This property is intentionally restricted to maintain framework abstraction and prevent direct dependency on specific agent implementations.</p> <p>If you need functionality that relies on accessing the underlying agent: 1. Consider if the functionality can be added to the AnyAgent interface 2. Submit a GitHub issue describing your use case 3. Contribute a PR implementing the needed functionality</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Always raised when this property is accessed</p>"},{"location":"api/#any_agent.frameworks.AnyAgent.tools","title":"<code>tools</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the tools used by the agent. This property is read-only and cannot be modified.</p>"},{"location":"api/#any_agent.frameworks.AnyAgent.run","title":"<code>run(prompt)</code>  <code>abstractmethod</code>","text":"<p>Run the agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@abstractmethod\ndef run(self, prompt: str) -&gt; Any:\n    \"\"\"Run the agent with the given prompt.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#any_agent.frameworks.LangchainAgent","title":"<code>LangchainAgent</code>","text":"<p>               Bases: <code>AnyAgent</code></p> <p>LangChain agent implementation that handles both loading and running.</p> Source code in <code>src/any_agent/frameworks/langchain.py</code> <pre><code>class LangchainAgent(AnyAgent):\n    \"\"\"LangChain agent implementation that handles both loading and running.\"\"\"\n\n    def __init__(\n        self, config: AgentConfig, managed_agents: Optional[list[AgentConfig]] = None\n    ):\n        self.managed_agents = managed_agents\n        self.config = config\n        self._agent = None\n        self._tools = []\n        self._load_agent()\n\n    @logger.catch(reraise=True)\n    def _load_agent(self) -&gt; None:\n        \"\"\"Load the LangChain agent with the given configuration.\"\"\"\n        if not langchain_available:\n            raise ImportError(\n                \"You need to `pip install langchain langgraph` to use this agent\"\n            )\n\n        if not self.config.tools:\n            self.config.tools = [\n                \"any_agent.tools.search_web\",\n                \"any_agent.tools.visit_webpage\",\n            ]\n\n        if self.managed_agents:\n            raise NotImplementedError(\"langchain managed agents are not supported yet\")\n\n        imported_tools, mcp_managers = import_and_wrap_tools(\n            self.config.tools, agent_framework=AgentFramework.LANGCHAIN\n        )\n\n        # Extract tools from MCP managers and add them to the imported_tools list\n        for manager in mcp_managers:\n            imported_tools.extend(manager.tools)\n\n        if \"/\" in self.config.model_id:\n            model_provider, model_id = self.config.model_id.split(\"/\")\n            model = init_chat_model(\n                model=model_id,\n                model_provider=model_provider,\n                **self.config.model_args or {},\n            )\n        else:\n            model = init_chat_model(\n                self.config.model_id, **self.config.model_args or {}\n            )\n\n        self._agent: CompiledGraph = create_react_agent(\n            model=model,\n            tools=imported_tools,\n            prompt=self.config.instructions,\n            **self.config.agent_args or {},\n        )\n        # Langgraph doesn't let you easily access what tools are loaded from the CompiledGraph, so we'll store a list of them in this class\n        self._tools = imported_tools\n\n    @logger.catch(reraise=True)\n    def run(self, prompt: str) -&gt; Any:\n        \"\"\"Run the LangChain agent with the given prompt.\"\"\"\n        inputs = {\"messages\": [(\"user\", prompt)]}\n        message = None\n        for s in self._agent.stream(inputs, stream_mode=\"values\"):\n            message = s[\"messages\"][-1]\n            if isinstance(message, tuple):\n                logger.debug(message)\n            else:\n                message.pretty_print()\n        return message\n\n    @property\n    def tools(self) -&gt; List[str]:\n        \"\"\"\n        Return the tools used by the agent.\n        This property is read-only and cannot be modified.\n        \"\"\"\n        return self._tools\n</code></pre>"},{"location":"api/#any_agent.frameworks.LangchainAgent.tools","title":"<code>tools</code>  <code>property</code>","text":"<p>Return the tools used by the agent. This property is read-only and cannot be modified.</p>"},{"location":"api/#any_agent.frameworks.LangchainAgent.run","title":"<code>run(prompt)</code>","text":"<p>Run the LangChain agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/langchain.py</code> <pre><code>@logger.catch(reraise=True)\ndef run(self, prompt: str) -&gt; Any:\n    \"\"\"Run the LangChain agent with the given prompt.\"\"\"\n    inputs = {\"messages\": [(\"user\", prompt)]}\n    message = None\n    for s in self._agent.stream(inputs, stream_mode=\"values\"):\n        message = s[\"messages\"][-1]\n        if isinstance(message, tuple):\n            logger.debug(message)\n        else:\n            message.pretty_print()\n    return message\n</code></pre>"},{"location":"api/#any_agent.frameworks.LlamaIndexAgent","title":"<code>LlamaIndexAgent</code>","text":"<p>               Bases: <code>AnyAgent</code></p> <p>LLamaIndex agent implementation that handles both loading and running.</p> Source code in <code>src/any_agent/frameworks/llama_index.py</code> <pre><code>class LlamaIndexAgent(AnyAgent):\n    \"\"\"LLamaIndex agent implementation that handles both loading and running.\"\"\"\n\n    def __init__(\n        self, config: AgentConfig, managed_agents: Optional[list[AgentConfig]] = None\n    ):\n        self.managed_agents: Optional[list[AgentConfig]] = managed_agents\n        self.config: AgentConfig = config\n        self._agent = None\n        self._load_agent()\n\n    def _get_model(self, agent_config: AgentConfig):\n        \"\"\"Get the model configuration for a llama_index agent.\"\"\"\n        if not agent_config.model_type:\n            agent_config.model_type = DEFAULT_MODEL_CLASS\n        module, class_name = agent_config.model_type.split(\".\")\n        model_type = getattr(\n            importlib.import_module(f\"llama_index.llms.{module}\"), class_name\n        )\n\n        return model_type(model=agent_config.model_id, **agent_config.model_args or {})\n\n    @logger.catch(reraise=True)\n    def _load_agent(self) -&gt; None:\n        \"\"\"Load the LLamaIndex agent with the given configuration.\"\"\"\n        if not llama_index_available:\n            raise ImportError(\"You need to `pip install llama-index` to use this agent\")\n\n        if not self.config.tools:\n            self.config.tools = [\n                \"any_agent.tools.search_web\",\n                \"any_agent.tools.visit_webpage\",\n            ]\n\n        if self.managed_agents:\n            raise NotImplementedError(\n                \"llama-index managed agents are not supported yet\"\n            )\n\n        imported_tools, mcp_managers = import_and_wrap_tools(\n            self.config.tools, agent_framework=AgentFramework.LLAMAINDEX\n        )\n\n        # Extract tools from MCP managers and add them to the imported_tools list\n        for manager in mcp_managers:\n            imported_tools.extend(manager.tools)\n\n        self._agent = ReActAgent(\n            name=self.config.name,\n            tools=imported_tools,\n            llm=self._get_model(self.config),\n            **self.config.agent_args or {},\n        )\n\n    async def _async_run(self, prompt):\n        result = await self._agent.run(prompt)\n        return result\n\n    @logger.catch(reraise=True)\n    def run(self, prompt: str) -&gt; Any:\n        \"\"\"Run the LlamaIndex agent with the given prompt.\"\"\"\n        import asyncio\n\n        return asyncio.run(self._async_run(prompt))\n\n    @property\n    def tools(self) -&gt; List[str]:\n        \"\"\"\n        Return the tools used by the agent.\n        This property is read-only and cannot be modified.\n        \"\"\"\n        return self._agent.tools\n</code></pre>"},{"location":"api/#any_agent.frameworks.LlamaIndexAgent.tools","title":"<code>tools</code>  <code>property</code>","text":"<p>Return the tools used by the agent. This property is read-only and cannot be modified.</p>"},{"location":"api/#any_agent.frameworks.LlamaIndexAgent.run","title":"<code>run(prompt)</code>","text":"<p>Run the LlamaIndex agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/llama_index.py</code> <pre><code>@logger.catch(reraise=True)\ndef run(self, prompt: str) -&gt; Any:\n    \"\"\"Run the LlamaIndex agent with the given prompt.\"\"\"\n    import asyncio\n\n    return asyncio.run(self._async_run(prompt))\n</code></pre>"},{"location":"api/#any_agent.frameworks.OpenAIAgent","title":"<code>OpenAIAgent</code>","text":"<p>               Bases: <code>AnyAgent</code></p> <p>OpenAI agent implementation that handles both loading and running.</p> Source code in <code>src/any_agent/frameworks/openai.py</code> <pre><code>class OpenAIAgent(AnyAgent):\n    \"\"\"OpenAI agent implementation that handles both loading and running.\"\"\"\n\n    def __init__(\n        self, config: AgentConfig, managed_agents: Optional[list[AgentConfig]] = None\n    ):\n        self.managed_agents = managed_agents\n        self.config = config\n        self._agent = None\n        self._load_agent()\n\n    def _get_model(self, agent_config: AgentConfig):\n        \"\"\"Get the model configuration for an OpenAI agent.\"\"\"\n        model_args = agent_config.model_args or {}\n        api_key_var = model_args.pop(\"api_key_var\", None)\n        base_url = model_args.pop(\"base_url\", None)\n        if api_key_var and base_url:\n            external_client = AsyncOpenAI(\n                api_key=os.environ[api_key_var],\n                base_url=base_url,\n            )\n            return OpenAIChatCompletionsModel(\n                model=agent_config.model_id,\n                openai_client=external_client,\n            )\n        return agent_config.model_id\n\n    @logger.catch(reraise=True)\n    def _load_agent(self) -&gt; None:\n        \"\"\"Load the OpenAI agent with the given configuration.\"\"\"\n        if not agents_available:\n            raise ImportError(\n                \"You need to `pip install openai-agents` to use this agent\"\n            )\n\n        if not self.managed_agents and not self.config.tools:\n            self.config.tools = [\n                \"any_agent.tools.search_web\",\n                \"any_agent.tools.visit_webpage\",\n            ]\n        tools, mcp_servers = import_and_wrap_tools(\n            self.config.tools, agent_framework=AgentFramework.OPENAI\n        )\n\n        handoffs = []\n        if self.managed_agents:\n            for managed_agent in self.managed_agents:\n                managed_tools, managed_mcp_servers = import_and_wrap_tools(\n                    managed_agent.tools, agent_framework=AgentFramework.OPENAI\n                )\n                kwargs = {}\n                if managed_agent.model_args:\n                    kwargs[\"model_settings\"] = managed_agent.model_args\n                instance = Agent(\n                    name=managed_agent.name,\n                    instructions=get_instructions(managed_agent.instructions),\n                    model=self._get_model(managed_agent),\n                    tools=managed_tools,\n                    mcp_servers=[\n                        managed_mcp_server.server\n                        for managed_mcp_server in managed_mcp_servers\n                    ],\n                    **kwargs,\n                )\n                if managed_agent.handoff:\n                    handoffs.append(instance)\n                else:\n                    tools.append(\n                        instance.as_tool(\n                            tool_name=instance.name,\n                            tool_description=managed_agent.description\n                            or f\"Use the agent: {managed_agent.name}\",\n                        )\n                    )\n\n        kwargs = self.config.agent_args or {}\n        if self.config.model_args:\n            kwargs[\"model_settings\"] = self.config.model_args\n        self._agent = Agent(\n            name=self.config.name,\n            instructions=self.config.instructions,\n            model=self._get_model(self.config),\n            handoffs=handoffs,\n            tools=tools,\n            mcp_servers=[mcp_server.server for mcp_server in mcp_servers],\n            **kwargs,\n        )\n\n    @logger.catch(reraise=True)\n    def run(self, prompt: str) -&gt; Any:\n        \"\"\"Run the OpenAI agent with the given prompt.\"\"\"\n        if not agents_available:\n            raise ImportError(\n                \"You need to `pip install openai-agents` to use this agent\"\n            )\n\n        result = Runner.run_sync(self._agent, prompt, max_turns=OPENAI_MAX_TURNS)\n        return result\n\n    @property\n    def tools(self) -&gt; List[str]:\n        \"\"\"\n        Return the tools used by the agent.\n        This property is read-only and cannot be modified.\n        \"\"\"\n        if hasattr(self, \"_agent\"):\n            # Extract tool names from the agent's tools\n            tools = [tool.name for tool in self._agent.tools]\n            # Add MCP tools to the list\n            for mcp_server in self._agent.mcp_servers:\n                tools_in_mcp = mcp_server._tools_list\n                server_name = mcp_server.name.replace(\" \", \"_\")\n                if tools_in_mcp:\n                    tools.extend(\n                        [f\"{server_name}_{tool.name}\" for tool in tools_in_mcp]\n                    )\n                else:\n                    raise ValueError(f\"No tools found in MCP {server_name}\")\n        else:\n            logger.warning(\"Agent not loaded or does not have tools.\")\n            tools = []\n        return tools\n</code></pre>"},{"location":"api/#any_agent.frameworks.OpenAIAgent.tools","title":"<code>tools</code>  <code>property</code>","text":"<p>Return the tools used by the agent. This property is read-only and cannot be modified.</p>"},{"location":"api/#any_agent.frameworks.OpenAIAgent.run","title":"<code>run(prompt)</code>","text":"<p>Run the OpenAI agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/openai.py</code> <pre><code>@logger.catch(reraise=True)\ndef run(self, prompt: str) -&gt; Any:\n    \"\"\"Run the OpenAI agent with the given prompt.\"\"\"\n    if not agents_available:\n        raise ImportError(\n            \"You need to `pip install openai-agents` to use this agent\"\n        )\n\n    result = Runner.run_sync(self._agent, prompt, max_turns=OPENAI_MAX_TURNS)\n    return result\n</code></pre>"},{"location":"api/#any_agent.frameworks.SmolagentsAgent","title":"<code>SmolagentsAgent</code>","text":"<p>               Bases: <code>AnyAgent</code></p> <p>Smolagents agent implementation that handles both loading and running.</p> Source code in <code>src/any_agent/frameworks/smolagents.py</code> <pre><code>class SmolagentsAgent(AnyAgent):\n    \"\"\"Smolagents agent implementation that handles both loading and running.\"\"\"\n\n    def __init__(\n        self, config: AgentConfig, managed_agents: Optional[list[AgentConfig]] = None\n    ):\n        self.managed_agents = managed_agents\n        self.config = config\n        self._agent = None\n        self._load_agent()\n\n    def _get_model(self, agent_config: AgentConfig):\n        \"\"\"Get the model configuration for a smolagents agent.\"\"\"\n        model_type = getattr(smolagents, agent_config.model_type or DEFAULT_MODEL_CLASS)\n        kwargs = {\n            \"model_id\": agent_config.model_id,\n        }\n        model_args = agent_config.model_args or {}\n        if api_key_var := model_args.pop(\"api_key_var\", None):\n            kwargs[\"api_key\"] = os.environ[api_key_var]\n        return model_type(**kwargs, **model_args)\n\n    def _merge_mcp_tools(self, mcp_servers):\n        \"\"\"Merge MCP tools from different servers.\"\"\"\n        tools = []\n        for mcp_server in mcp_servers:\n            tools.extend(mcp_server.tools)\n        return tools\n\n    @logger.catch(reraise=True)\n    def _load_agent(self) -&gt; None:\n        \"\"\"Load the Smolagents agent with the given configuration.\"\"\"\n        if not smolagents_available:\n            raise ImportError(\"You need to `pip install smolagents` to use this agent\")\n\n        if not self.managed_agents and not self.config.tools:\n            self.config.tools = [\n                \"any_agent.tools.search_web\",\n                \"any_agent.tools.visit_webpage\",\n            ]\n\n        tools, mcp_servers = import_and_wrap_tools(\n            self.config.tools, agent_framework=AgentFramework.SMOLAGENTS\n        )\n        tools.extend(self._merge_mcp_tools(mcp_servers))\n\n        managed_agents_instanced = []\n        if self.managed_agents:\n            for managed_agent in self.managed_agents:\n                agent_type = getattr(\n                    smolagents, managed_agent.agent_type or DEFAULT_AGENT_TYPE\n                )\n                managed_tools, managed_mcp_servers = import_and_wrap_tools(\n                    managed_agent.tools, agent_framework=AgentFramework.SMOLAGENTS\n                )\n                tools.extend(self._merge_mcp_tools(managed_mcp_servers))\n                managed_agent_instance = agent_type(\n                    name=managed_agent.name,\n                    model=self._get_model(managed_agent),\n                    tools=managed_tools,\n                    verbosity_level=-1,  # OFF\n                    description=managed_agent.description\n                    or f\"Use the agent: {managed_agent.name}\",\n                )\n                if managed_agent.instructions:\n                    managed_agent_instance.prompt_templates[\"system_prompt\"] = (\n                        managed_agent.instructions\n                    )\n                managed_agents_instanced.append(managed_agent_instance)\n\n        main_agent_type = getattr(\n            smolagents, self.config.agent_type or DEFAULT_AGENT_TYPE\n        )\n\n        self._agent: MultiStepAgent = main_agent_type(\n            name=self.config.name,\n            model=self._get_model(self.config),\n            tools=tools,\n            verbosity_level=-1,  # OFF\n            managed_agents=managed_agents_instanced,\n            **self.config.agent_args or {},\n        )\n\n        if self.config.instructions:\n            self._agent.prompt_templates[\"system_prompt\"] = self.config.instructions\n\n    @logger.catch(reraise=True)\n    def run(self, prompt: str) -&gt; Any:\n        \"\"\"Run the Smolagents agent with the given prompt.\"\"\"\n        result = self._agent.run(prompt)\n        return result\n\n    @property\n    def tools(self) -&gt; List[str]:\n        \"\"\"\n        Return the tools used by the agent.\n        This property is read-only and cannot be modified.\n        \"\"\"\n        return self._agent.tools\n</code></pre>"},{"location":"api/#any_agent.frameworks.SmolagentsAgent.tools","title":"<code>tools</code>  <code>property</code>","text":"<p>Return the tools used by the agent. This property is read-only and cannot be modified.</p>"},{"location":"api/#any_agent.frameworks.SmolagentsAgent.run","title":"<code>run(prompt)</code>","text":"<p>Run the Smolagents agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/smolagents.py</code> <pre><code>@logger.catch(reraise=True)\ndef run(self, prompt: str) -&gt; Any:\n    \"\"\"Run the Smolagents agent with the given prompt.\"\"\"\n    result = self._agent.run(prompt)\n    return result\n</code></pre>"},{"location":"api/#any_agent.instructions","title":"<code>any_agent.instructions</code>","text":""},{"location":"api/#any_agent.instructions.get_instructions","title":"<code>get_instructions(instructions)</code>","text":"<p>Get the instructions from an external module.</p> <p>Parameters:</p> Name Type Description Default <code>instructions</code> <code>str | None</code> <p>Depending on the syntax used:</p> <ul> <li> <p>An import that points to a string in an external module.     For example: <code>agents.extensions.handoff_prompt.RECOMMENDED_PROMPT_PREFIX</code>.     The string will be imported from the external module.</p> </li> <li> <p>A regular string containing instructions.     For example: <code>You are a helpful assistant</code>.     The string will be returned as is.</p> </li> </ul> required <p>Returns:</p> Type Description <code>str | None</code> <p>Either the imported string or the input string as is.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>instructions</code> is an import but doesn't point to a string.</p> Source code in <code>src/any_agent/instructions/imports.py</code> <pre><code>def get_instructions(instructions: str | None) -&gt; str | None:\n    \"\"\"Get the instructions from an external module.\n\n    Args:\n        instructions: Depending on the syntax used:\n\n            - An import that points to a string in an external module.\n                For example: `agents.extensions.handoff_prompt.RECOMMENDED_PROMPT_PREFIX`.\n                The string will be imported from the external module.\n\n            - A regular string containing instructions.\n                For example: `You are a helpful assistant`.\n                The string will be returned as is.\n\n    Returns:\n        Either the imported string or the input string as is.\n\n    Raises:\n        ValueError: If `instructions` is an import but doesn't point to a string.\n    \"\"\"\n    if instructions and is_import(instructions):\n        module, obj = instructions.rsplit(\".\", 1)\n        module = importlib.import_module(module)\n        imported = getattr(module, obj)\n        if not isinstance(imported, str):\n            raise ValueError(\n                \"Instructions were identified as an import\"\n                f\" but the value imported is not a string:  {instructions}\"\n            )\n        return imported\n    return instructions\n</code></pre>"},{"location":"api/#any_agent.tools","title":"<code>any_agent.tools</code>","text":""},{"location":"api/#any_agent.tools.ask_user_verification","title":"<code>ask_user_verification(query)</code>","text":"<p>Asks user to verify the given <code>query</code>.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question that requires verification.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def ask_user_verification(query: str) -&gt; str:\n    \"\"\"Asks user to verify the given `query`.\n\n    Args:\n        query: The question that requires verification.\n    \"\"\"\n    return input(f\"{query} =&gt; Type your answer here:\")\n</code></pre>"},{"location":"api/#any_agent.tools.search_web","title":"<code>search_web(query)</code>","text":"<p>Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query to perform.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The top search results.</p> Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\n\n    Args:\n        query (str): The search query to perform.\n\n    Returns:\n        The top search results.\n    \"\"\"\n    ddgs = DDGS()\n    results = ddgs.text(query, max_results=10)\n    return \"\\n\".join(\n        f\"[{result['title']}]({result['href']})\\n{result['body']}\" for result in results\n    )\n</code></pre>"},{"location":"api/#any_agent.tools.send_console_message","title":"<code>send_console_message(user, query)</code>","text":"<p>Sends the specified user a message via console and returns their response. Args:     query: The question to ask the user.     user: The user to ask the question to. Returns:     str: The user's response.</p> Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def send_console_message(user: str, query: str) -&gt; str:\n    \"\"\"Sends the specified user a message via console and returns their response.\n    Args:\n        query: The question to ask the user.\n        user: The user to ask the question to.\n    Returns:\n        str: The user's response.\n    \"\"\"\n    return input(f\"{query}\\n{user}&gt;&gt;\")\n</code></pre>"},{"location":"api/#any_agent.tools.show_final_answer","title":"<code>show_final_answer(answer)</code>","text":"<p>Show the final answer to the user.</p> <p>Parameters:</p> Name Type Description Default <code>answer</code> <code>str</code> <p>The final answer.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_final_answer(answer: str) -&gt; None:\n    \"\"\"Show the final answer to the user.\n\n    Args:\n        answer: The final answer.\n    \"\"\"\n    logger.info(f\"Final answer: {answer}\")\n    return answer\n</code></pre>"},{"location":"api/#any_agent.tools.show_plan","title":"<code>show_plan(plan)</code>","text":"<p>Show the current plan to the user.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>str</code> <p>The current plan.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_plan(plan: str) -&gt; None:\n    \"\"\"Show the current plan to the user.\n\n    Args:\n        plan: The current plan.\n    \"\"\"\n    logger.info(f\"Current plan: {plan}\")\n    return plan\n</code></pre>"},{"location":"api/#any_agent.tools.visit_webpage","title":"<code>visit_webpage(url)</code>","text":"<p>Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The url of the webpage to visit.</p> required Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def visit_webpage(url: str) -&gt; str:\n    \"\"\"Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.\n\n    Args:\n        url: The url of the webpage to visit.\n    \"\"\"\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n\n        markdown_content = markdownify(response.text).strip()\n\n        markdown_content = re.sub(r\"\\n{2,}\", \"\\n\", markdown_content)\n\n        return _truncate_content(markdown_content, 10000)\n    except RequestException as e:\n        return f\"Error fetching the webpage: {str(e)}\"\n    except Exception as e:\n        return f\"An unexpected error occurred: {str(e)}\"\n</code></pre>"},{"location":"api/#any_agent.tracing","title":"<code>any_agent.tracing</code>","text":""},{"location":"api/#any_agent.tracing.setup_tracing","title":"<code>setup_tracing(agent_framework, output_dir='traces')</code>","text":"<p>Setup tracing for <code>agent_framework</code> using <code>openinference.instrumentation</code>.</p> <p>Parameters:</p> Name Type Description Default <code>agent_framework</code> <code>AgentFramework</code> <p>The type of agent being used.</p> required <code>output_dir</code> <code>str</code> <p>The directory where the traces will be stored. Defaults to \"traces\".</p> <code>'traces'</code> <p>Returns:     str: The name of the JSON file where traces will be stored.</p> Source code in <code>src/any_agent/tracing.py</code> <pre><code>def setup_tracing(agent_framework: AgentFramework, output_dir: str = \"traces\") -&gt; str:\n    \"\"\"Setup tracing for `agent_framework` using `openinference.instrumentation`.\n\n    Args:\n        agent_framework (AgentFramework): The type of agent being used.\n        output_dir (str): The directory where the traces will be stored.\n            Defaults to \"traces\".\n    Returns:\n        str: The name of the JSON file where traces will be stored.\n    \"\"\"\n    tracer_provider, file_name = _get_tracer_provider(agent_framework, output_dir)\n    if agent_framework == AgentFramework.OPENAI:\n        from openinference.instrumentation.openai_agents import OpenAIAgentsInstrumentor\n\n        OpenAIAgentsInstrumentor().instrument(tracer_provider=tracer_provider)\n    elif agent_framework == AgentFramework.SMOLAGENTS:\n        from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n\n        SmolagentsInstrumentor().instrument(tracer_provider=tracer_provider)\n    elif agent_framework == AgentFramework.LANGCHAIN:\n        from openinference.instrumentation.langchain import LangChainInstrumentor\n\n        LangChainInstrumentor().instrument(tracer_provider=tracer_provider)\n    elif agent_framework == AgentFramework.LLAMAINDEX:\n        from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n\n        LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)\n    else:\n        raise NotImplementedError(f\"{agent_framework} tracing is not supported.\")\n    return file_name\n</code></pre>"},{"location":"api/#any_agent.config.AgentFramework","title":"<code>any_agent.config.AgentFramework</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentFramework(str, Enum):\n    OPENAI = \"openai\"\n    LANGCHAIN = \"langchain\"\n    SMOLAGENTS = \"smolagents\"\n    LLAMAINDEX = \"llama_index\"\n</code></pre>"},{"location":"api/#any_agent.config.AgentConfig","title":"<code>any_agent.config.AgentConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n    model_id: str\n    name: str = \"any_agent\"\n    instructions: str | None = None\n    tools: list[str | MCPTool] = Field(default_factory=list)\n    handoff: bool = False\n    agent_type: str | None = None\n    agent_args: dict | None = None\n    model_type: str | None = None\n    model_args: dict | None = None\n    description: str | None = None\n</code></pre>"},{"location":"api/#any_agent.config.MCPTool","title":"<code>any_agent.config.MCPTool</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPTool(BaseModel):\n    command: str\n    args: list[str]\n    tools: list[str] | None = None\n</code></pre>"},{"location":"evaluation/","title":"Agent Evaluation","text":"<p>Warning</p> <p>The codebase for evaluation is under development and is not yet stable. Use with caution, we welcome contributions.</p> <p>Evaluation using any_agent.evaluation is designed to be a \"trace-first\" evaluation. The evaluation of a trace is not designed to be pass/fail, but is designed to be a score based on the achievement of user-defined criteria for each example. Agent systems are hyper-specific to each use case, and it's difficult to provide a single set of metrics that would reliably provide the insight needed to make a decision about the effectiveness of an agent.</p> <p>Using any-agent evaluation, you can specify any criteria you wish, and through LLM-as-a-judge technology, any-agent will evaluate which criteria are satisfied.</p>"},{"location":"evaluation/#example","title":"Example","text":"<p>Using the unified tracing format provided by any-agent's tracing functionality, the trace can be evaluated with user defined criteria. The steps for evaluating an agent are as follows:</p> <ol> <li>Run an agent using any-agent, which will produce a json file with the trace. For example</li> </ol> <p><pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\nfrom any_agent.tracing import setup_tracing\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\"any_agent.tools.search_web\"]\n)\nframework=AgentFramework(\"langchain\")\ntracing_path = setup_tracing(framework, \"output\")\nagent = AnyAgent.create(framework, main_agent)\n\nagent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\n</code></pre> 1. Define a test case in a yaml file, e.g.</p> <pre><code># The criteria will be passed to an llm-as-a-judge along with the trace to have as context\n# The points specify the weight given to each criteria when producing the final score\nllm_judge: openai/gpt-4o\ncheckpoints:\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n  - points: 1\n    criteria: |\n        Ensure that the agent ran a python snippet to combine the information\n        from the info retrieved from the web searches\n\n# Optionally, you can check whether the final answer is what was expected. Checking this value does not use an LLM\nground_truth:\n  - name: Time\n    points: 5\n    value: 9.63\n</code></pre> <ol> <li>Run the evaluation using the test case and trace. <pre><code>from any_agent.evaluation.test_case import TestCase\nfrom any_agent.evaluation.evaluate import evaluate_telemetry\ntest_case = TestCase.from_yaml(\"/path/to/test/case/yaml\")\nevaluate_telemetry(test_case, '/path/to/telemetry/output')\n</code></pre> The output will look something like this:</li> </ol> <pre><code>Passed:\n- Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n- The agent called the search_web tool with the query 'Pont des Arts length' as indicated in the telemetry evidence.\n\nPassed:\n- Ensure that the agent ran a python snippet to combine the information from the info retrieved from the web searches\n- The agent successfully ran a Python snippet to calculate the time it would take for a leopard to run through the Pont des Arts using the length of the bridge retrieved from a web search.\n\nFailed:\n- Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n- The agent called the search_web tool to find the length of Pont des Arts, but did not call it to access the top speed of a leopard.\n\nFailed:\n- Check if Time is approximately '9.63'.\n- The calculated time in the agent's answer is 9.62, not 9.63.\n\nFailed:\n- Is the answer a direct match?\n- Partial Match (F1) score is 0.0\nPassed checkpoints: 2\nFailed checkpoints: 3\n=====================================\nScore: 2/9\n=====================================\n\nReading existing output from output/results.json\nWriting output to output/results.json\n</code></pre>"},{"location":"frameworks/","title":"Agent Frameworks","text":"<p>Here you can find the frameworks currently supported in <code>any-agent</code>, along with some basic examples.</p> <p>Info</p> <p>If you are missing any agent framework, check the existing issues to see if it has been already requested and comment/upvote on that issue.</p> <p>If there is no existing issue, don't hesitate to request and/or contribute it.</p> \ud83e\udd9c\ud83d\udd17 LangChain\ud83d\uddc2\ufe0f LlamaIndex \ud83e\udd99OpenAI Agents\ud83e\udd17 smolagents <p>LangChain Repo</p> <pre><code>agent = AnyAgent.create(\n    framework=AgentFramework(\"langchain\"),\n    main_agent=AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>LLamaIndex Repo</p> <pre><code>agent = AnyAgent.create(\n    framework=AgentFramework(\"llama_index\"),\n    main_agent=AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>OpenAI Agents Repo</p> <pre><code>agent = AnyAgent.create(\n    framework=AgentFramework(\"openai\"),\n    main_agent=AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>smolagents Repo</p> <pre><code>agent = AnyAgent.create(\n    framework=AgentFramework(\"smolagents\"),\n    main_agent=AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"instructions/","title":"Agent Instructions","text":"<p><code>any-agent</code> provides 2 options to specify the instructions for your agent: <code>Import</code> and <code>String</code>.</p> <p>In the first case, the import should point to a Python string.</p> <p>Warning</p> <p>Some frameworks use complex default instructions for specific agent implementations. Completely replacing those instructions might result in unexpected behavior.</p> <p>In those cases, you might want to instead copy-paste and extend the default instructions. For example, check the <code>CodeAgent</code> default instructions in <code>smolagents</code>.</p> ImportString <p>For a variable that you would import like:</p> <pre><code>from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n</code></pre> <p>The expected syntax is <code>agents.extensions.handoff_prompt.RECOMMENDED_PROMPT_PREFIX</code></p> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\n\nframework = AgentFramework(\"openai\")\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    instructions=\"agents.extensions.handoff_prompt.RECOMMENDED_PROMPT_PREFIX\",\n)\n</code></pre> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\n\nframework = AgentFramework(\"openai\")\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    instructions=\"You are a helpful assistant that can navigate the web\",\n    tools=[\n        \"any_agent.tools.search_web\",\n        \"any_agent.tools.visit_webpage\"\n    ]\n)\n</code></pre>"},{"location":"tools/","title":"Agent Tools","text":"<p><code>any-agent</code> provides 3 options to specify what <code>tools</code> are available to your agent: <code>Import</code>, <code>Callable</code>, and <code>MCP</code> (Model Context Protocol).</p> <p>You can use any combination of options in the same agent.</p> <p>Under the hood, <code>any-agent</code> takes care of importing (for the first case) and wrapping (in any case needed) the tool so it becomes usable by the selected framework.</p> ImportCallableMCP <p>For a tool that you would import like:</p> <pre><code>from any_agent.tools import search_web\n</code></pre> <p>The expected syntax is <code>any_agent.tools.search_web</code></p> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\n\nframework = AgentFramework(\"openai\")\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        \"langchain_community.tools.TavilySearchResults\",\n        \"any_agent.tools.visit_webpage\"\n    ]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\nfrom langchain_community.tools import TavilySearchResults\n\nframework = AgentFramework(\"openai\")\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        TavilySearchResults(\n            max_results=3,\n            include_raw_content=True,\n        ),\n    ]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\nfrom any_agent.config import MCPTool\n\nframework = AgentFramework(\"openai\")\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPTool(\n            command=\"docker\",\n            args=[\"run\", \"-i\", \"--rm\", \"mcp/fetch\"],\n            tools=[\"fetch\"]\n        ),\n    ]\n)\n</code></pre>"},{"location":"tracing/","title":"Agent Tracing","text":"<p><code>any-agent</code> uses <code>openinference</code> to generate standardized OpenTelemetry traces for any of the supported agent frameworks.</p>"},{"location":"tracing/#example","title":"Example","text":"<p>To enable tracing, call <code>setup_tracing</code> passing the selected framework.</p> <pre><code>from any_agent import AgentConfig, AgentFramework, AnyAgent\nfrom any_agent.tracing import setup_tracing\n\nframework = AgentFramework(\"openai\")\n\nsetup_tracing(framework)\n\nagent = AnyAgent.create(\n        main_agent=AgentConfig(\n        model_id=\"gpt-4o\",\n        tools=[\"any_agent.tools.search_web\"]\n    )\n)\nagent.run(\"Which agent framework is the best?\")\n</code></pre>"},{"location":"tracing/#outputs","title":"Outputs","text":"<p><code>setup_tracing</code> will produce standardized console output regardless of the framework used:</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 LLM \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ninput: Which agent framework is the best?\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 TOOL \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntool_name: search_web\ninput: {'query': 'best agent framework 2023'}\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ... The agent architecture came to life in March 2023, but it wasn't until a few    \u2502\n\u2502 months later that it took a grip in the open-source community. The agent landscape may still seem like a \"mad scientist\" kind of experiment, but there are \u2502\n\u2502 already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks Top 10 AI Agent Frameworks - gocodeo.com The    \u2502\n\u2502 ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog     \u2502\n\u2502 Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \"just prompt it and see what happens.\" As AI     \u2502\n\u2502 agents inch closer to production ... List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ... 3. Bee Agent Framework (IBM) Introduction:    \u2502\n\u2502 The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to  \u2502\n\u2502 integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ... Top 9  \u2502\n\u2502 AI Agent Frameworks as of April 2025 | Shakudo AutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by   \u2502\n\u2502 automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build,  \u2502\n\u2502 fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ... 10 best AI    \u2502\n\u2502 agent frameworks - blog.apify.com Best AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a      \u2502\n\u2502 scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it  \u2502\n\u2502 easier to integrate with third-party tools, handle cloud hosting, monitor ... Best 5 Frameworks To Build Multi-Agent AI Applications In this example, we   \u2502\n\u2502 specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run                       \u2502\n\u2502 reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework     \u2502\n\u2502 recently released by OpenAI. It is a lightweight multi-agent orchestration framework. Agentic Framework Showdown: We Tested 8 AI Agent Frameworks They     \u2502\n\u2502 reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of    \u2502\n\u2502 the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI;      \u2502\n\u2502 Langflow; LangGraph; LlamaIndex; n8n ... Comparing Open-Source AI Agent Frameworks - Langfuse Blog This post offers an in-depth look at some of the        \u2502\n\u2502 leading open-source AI agent frameworks out there: LangGraph, the OpenAI Agents SDK, Smolagents, CrewAI, AutoGen, Semantic Kernel, and LlamaIndex agents.  \u2502\n\u2502 By the time you finish reading, you should have a clearer view of each framework's sweet spot, how they differ, and where they excel in real ... Choosing  \u2502\n\u2502 the Right AI Agent Framework: LangGraph vs CrewAI vs OpenAI Swarm We chose LangGraph, CrewAI, and OpenAI Swarm because they represent the latest schools   \u2502\n\u2502 of thought in agent development. Here's a quick overview: LangGraph: As its name suggests, LangGraph bets on graph architecture as the best way to define  \u2502\n\u2502 and orchestrate agentic workflows. Unlike early versions of LangChain, LangGraph is a well designed framework with many robust and customizable features   \u2502\n\u2502 ... Best AI Agent Frameworks Your business demands the best AI agent framework to accelerate your project. It should support LLM integration, advanced     \u2502\n\u2502 reasoning, long-term memory, flexible tool coordination, and smooth collaboration between multiple agents. Here we discuss some AI agent frameworks that   \u2502\n\u2502 empower you to achieve unmatched levels of automation and intelligence.                                                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre> <p>In addition, an output JSON will be stored in the selected <code>output_dir</code>, which is <code>\"traces\"</code> by default:</p> <pre><code>[\n  {\n    \"name\": \"response\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xd4a8cd952e71e1d1\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:25.327409Z\",\n    \"end_time\": \"2025-04-07T10:20:26.813604Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"output.mime_type\": \"application/json\",\n      \"output.value\": \"{\\\"id\\\":\\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\",\\\"created_at\\\":1744021218.0,\\\"error\\\":null,\\\"incomplete_details\\\":null,\\\"instructions\\\":\\\"Search the web to answer\\\",\\\"metadata\\\":{},\\\"model\\\":\\\"gpt-4o-2024-08-06\\\",\\\"object\\\":\\\"response\\\",\\\"output\\\":[{\\\"arguments\\\":\\\"{\\\\\\\"query\\\\\\\":\\\\\\\"best agent framework 2023\\\\\\\"}\\\",\\\"call_id\\\":\\\"call_xCZMfOtnbmKS1nGDywFtmCcR\\\",\\\"name\\\":\\\"search_web\\\",\\\"type\\\":\\\"function_call\\\",\\\"id\\\":\\\"fc_67f3a6e351988192a79ec42d68fccbe001e7f8b6e38c7e7a\\\",\\\"status\\\":\\\"completed\\\"}],\\\"parallel_tool_calls\\\":false,\\\"temperature\\\":1.0,\\\"tool_choice\\\":\\\"auto\\\",\\\"tools\\\":[{\\\"name\\\":\\\"search_web\\\",\\\"parameters\\\":{\\\"properties\\\":{\\\"query\\\":{\\\"description\\\":\\\"The search query to perform.\\\",\\\"title\\\":\\\"Query\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"],\\\"title\\\":\\\"search_web_args\\\",\\\"type\\\":\\\"object\\\",\\\"additionalProperties\\\":false},\\\"strict\\\":true,\\\"type\\\":\\\"function\\\",\\\"description\\\":\\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\"}],\\\"top_p\\\":1.0,\\\"max_output_tokens\\\":null,\\\"previous_response_id\\\":null,\\\"reasoning\\\":{\\\"effort\\\":null,\\\"generate_summary\\\":null},\\\"status\\\":\\\"completed\\\",\\\"text\\\":{\\\"format\\\":{\\\"type\\\":\\\"text\\\"}},\\\"truncation\\\":\\\"disabled\\\",\\\"usage\\\":{\\\"input_tokens\\\":89,\\\"input_tokens_details\\\":{\\\"cached_tokens\\\":0},\\\"output_tokens\\\":20,\\\"output_tokens_details\\\":{\\\"reasoning_tokens\\\":0},\\\"total_tokens\\\":109},\\\"user\\\":null,\\\"store\\\":true}\",\n      \"llm.tools.0.tool.json_schema\": \"{\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"search_web\\\", \\\"description\\\": \\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\", \\\"parameters\\\": {\\\"properties\\\": {\\\"query\\\": {\\\"description\\\": \\\"The search query to perform.\\\", \\\"title\\\": \\\"Query\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"query\\\"], \\\"title\\\": \\\"search_web_args\\\", \\\"type\\\": \\\"object\\\", \\\"additionalProperties\\\": false}, \\\"strict\\\": true}}\",\n      \"llm.token_count.completion\": 89,\n      \"llm.token_count.prompt\": 20,\n      \"llm.token_count.total\": 109,\n      \"llm.output_messages.0.message.role\": \"assistant\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.id\": \"call_xCZMfOtnbmKS1nGDywFtmCcR\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.name\": \"search_web\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.arguments\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"llm.input_messages.0.message.role\": \"system\",\n      \"llm.input_messages.0.message.content\": \"Search the web to answer\",\n      \"llm.model_name\": \"gpt-4o-2024-08-06\",\n      \"llm.invocation_parameters\": \"{\\\"id\\\": \\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\", \\\"created_at\\\": 1744021218.0, \\\"instructions\\\": \\\"Search the web to answer\\\", \\\"metadata\\\": {}, \\\"model\\\": \\\"gpt-4o-2024-08-06\\\", \\\"object\\\": \\\"response\\\", \\\"parallel_tool_calls\\\": false, \\\"temperature\\\": 1.0, \\\"tool_choice\\\": \\\"auto\\\", \\\"top_p\\\": 1.0, \\\"reasoning\\\": {}, \\\"status\\\": \\\"completed\\\", \\\"text\\\": {\\\"format\\\": {\\\"type\\\": \\\"text\\\"}}, \\\"truncation\\\": \\\"disabled\\\", \\\"store\\\": true}\",\n      \"input.mime_type\": \"application/json\",\n      \"input.value\": \"[{\\\"content\\\": \\\"Which agent framework is the best?\\\", \\\"role\\\": \\\"user\\\"}]\",\n      \"llm.input_messages.1.message.role\": \"user\",\n      \"llm.input_messages.1.message.content\": \"Which agent framework is the best?\",\n      \"openinference.span.kind\": \"LLM\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n  {\n    \"name\": \"search_web\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xe8fa92007caee376\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:26.821732Z\",\n    \"end_time\": \"2025-04-07T10:20:28.420378Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"tool.name\": \"search_web\",\n      \"input.value\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"input.mime_type\": \"application/json\",\n      \"output.value\": \"[Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ...](https://www.taskade.com/blog/top-autonomous-agents/)\\nThe agent architecture came to life in March 2023, but it wasn't until a few months later that it took a grip in the open-source community. The agent landscape may still seem like a \\\"mad scientist\\\" kind of experiment, but there are already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks\\n[Top 10 AI Agent Frameworks - gocodeo.com](https://www.gocodeo.com/post/top-10-ai-agent-frameworks)\\nThe ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \\\"just prompt it and see what happens.\\\" As AI agents inch closer to production ...\\n[List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ...](https://www.devopsschool.com/blog/list-of-top-10-multi-agent-orchestrator-frameworks-for-deploying-ai-agents/)\\n3. Bee Agent Framework (IBM) Introduction: The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ...\\n[Top 9 AI Agent Frameworks as of April 2025 | Shakudo](https://www.shakudo.io/blog/top-9-ai-agent-frameworks)\\nAutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build, fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ...\\n[10 best AI agent frameworks - blog.apify.com](https://blog.apify.com/10-best-ai-agent-frameworks/)\\nBest AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it easier to integrate with third-party tools, handle cloud hosting, monitor ...\\n[Best 5 Frameworks To Build Multi-Agent AI Applications](https://getstream.io/blog/multiagent-ai-frameworks/)\\nIn this example, we specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework recently released by OpenAI. It is a lightweight multi-agent orchestration framework.\\n[Agentic Framework Showdown: We Tested 8 AI Agent Frameworks](https://www.willowtreeapps.com/craft/8-agentic-frameworks-tested)\\nThey reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI; Langflow; LangGraph; LlamaIndex; n8n ...\\n[Comparing Open-Source AI Agent Frameworks - Langfuse Blog](https://langfuse.com/blog/2025-03-19-ai-agent-comparison)\\nThis post offers an in-depth look at some of the leading open-source AI agent frameworks out there: LangGraph, the OpenAI Agents SDK, Smolagents, CrewAI, AutoGen, Semantic Kernel, and LlamaIndex agents. By the time you finish reading, you should have a clearer view of each framework's sweet spot, how they differ, and where they excel in real ...\\n[Choosing the Right AI Agent Framework: LangGraph vs CrewAI vs OpenAI Swarm](https://www.relari.ai/blog/ai-agent-framework-comparison-langgraph-crewai-openai-swarm)\\nWe chose LangGraph, CrewAI, and OpenAI Swarm because they represent the latest schools of thought in agent development. Here's a quick overview: LangGraph: As its name suggests, LangGraph bets on graph architecture as the best way to define and orchestrate agentic workflows. Unlike early versions of LangChain, LangGraph is a well designed framework with many robust and customizable features ...\\n[Best AI Agent Frameworks](https://www.folio3.ai/blog/ai-agent-frameworks/)\\nYour business demands the best AI agent framework to accelerate your project. It should support LLM integration, advanced reasoning, long-term memory, flexible tool coordination, and smooth collaboration between multiple agents. Here we discuss some AI agent frameworks that empower you to achieve unmatched levels of automation and intelligence.\",\n      \"openinference.span.kind\": \"TOOL\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n  ...\n</code></pre>"}]}